{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a27c000",
   "metadata": {},
   "source": [
    "# Multi-level flow with fully-connected networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e25bbc60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T15:12:30.213554Z",
     "start_time": "2022-03-30T15:12:29.378596Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import math\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# from jsonargparse.typing import PositiveInt, PositiveFloat, NonNegativeFloat\n",
    "\n",
    "import flows.phi_four as phi_four\n",
    "import flows.transforms as transforms\n",
    "import flows.utils as utils\n",
    "from flows.distributions import Prior, FreeScalarDistribution\n",
    "\n",
    "Tensor: TypeAlias = torch.Tensor\n",
    "BoolTensor: TypeAlias = torch.BoolTensor\n",
    "Module: TypeAlias = torch.nn.Module\n",
    "IterableDataset: TypeAlias = torch.utils.data.IterableDataset\n",
    "\n",
    "logging.getLogger().setLevel(\"WARNING\")\n",
    "\n",
    "#%load_ext lab_black\n",
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56efa29a",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89833b80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T15:12:33.114168Z",
     "start_time": "2022-03-30T15:12:33.093914Z"
    }
   },
   "outputs": [],
   "source": [
    "class CouplingLayer(Module):\n",
    "    def __init__(self, transform, net_spec: dict):\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        self.net_a = self.build_convnet(**net_spec)\n",
    "        self.net_b = self.build_convnet(**net_spec)\n",
    "\n",
    "    def build_convnet(\n",
    "        self,\n",
    "        hidden_shape: tuple[PositiveInt],\n",
    "        activation: Module = torch.nn.Tanh(),\n",
    "        final_activation: Module = torch.nn.Identity(),\n",
    "        kernel_size: PositiveInt = 3,\n",
    "        use_bias: bool = True,\n",
    "    ):\n",
    "        net_shape = [1, *hidden_shape, self.transform.params_dof]\n",
    "        activations = [activation for _ in hidden_shape] + [final_activation]\n",
    "\n",
    "        net = []\n",
    "        for in_channels, out_channels, activation in zip(\n",
    "            net_shape[:-1], net_shape[1:], activations\n",
    "        ):\n",
    "            convolution = torch.nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=1,\n",
    "                padding_mode=\"circular\",\n",
    "                stride=1,\n",
    "                bias=use_bias,\n",
    "            )\n",
    "            net.append(convolution)\n",
    "            net.append(activation)\n",
    "\n",
    "        return torch.nn.Sequential(*net)\n",
    "\n",
    "    def forward(self, x_full: Tensor, log_det_jacob: tensor) -> tuple[Tensor]:\n",
    "        n_batch, n_channels, l1, l2 = x_full.shape\n",
    "        if n_channels > 1:\n",
    "            x, h = torch.tensor_split(x_full, [1], dim=1)  # take first channel\n",
    "        else:\n",
    "            x = x_full\n",
    "        mask = utils.make_checkerboard((l1, l2)).to(x.device)\n",
    "        mask_expanded = mask.view(1, 1, l1, l2)\n",
    "\n",
    "        x_a = x[..., mask]\n",
    "        x_b = x[..., ~mask]\n",
    "\n",
    "        params_a = self.net_b(x.mul(~mask_expanded))[..., mask]\n",
    "        y_a, log_det_jacob_a = self.transform(x_a, params_a)\n",
    "\n",
    "        xy = torch.zeros_like(x)\n",
    "        xy[..., mask] = y_a\n",
    "\n",
    "        params_b = self.net_a(xy)[..., ~mask]\n",
    "        y_b, log_det_jacob_b = self.transform(x_b, params_b)\n",
    "\n",
    "        y = xy.clone()\n",
    "        y[..., ~mask] = y_b\n",
    "\n",
    "        if n_channels > 1:\n",
    "            y_full = torch.cat([y, h], dim=1)\n",
    "        else:\n",
    "            y_full = y\n",
    "\n",
    "        log_det_jacob.add_(log_det_jacob_a)\n",
    "        log_det_jacob.add_(log_det_jacob_b)\n",
    "\n",
    "        return y_full, log_det_jacob\n",
    "\n",
    "\n",
    "class UpsamplingLayer(Module):\n",
    "    def __init__(self, use_batch_dimension: bool = False):\n",
    "        super().__init__()\n",
    "        self.use_batch_dimension = use_batch_dimension\n",
    "\n",
    "        kernel = torch.stack(\n",
    "            [\n",
    "                Tensor([[1, 0], [0, 0]]),\n",
    "                Tensor([[0, 1], [0, 0]]),\n",
    "                Tensor([[0, 0], [1, 0]]),\n",
    "                Tensor([[0, 0], [0, 1]]),\n",
    "            ],\n",
    "            dim=0,\n",
    "        ).unsqueeze(dim=1)\n",
    "        assert kernel.shape == torch.Size([4, 1, 2, 2])\n",
    "\n",
    "        self.register_buffer(\"kernel\", kernel)\n",
    "\n",
    "    def forward(self, x: Tensor, log_det_jacob: Tensor) -> tuple[Tensor]:\n",
    "        \"\"\"Upsample 1 lattice site -> 4 lattice sites.\"\"\"\n",
    "        n_batch, _, l1, l2 = x.shape\n",
    "        assert (l1 % 2 == 0) and (l2 % 2 == 0)\n",
    "\n",
    "        y = F.conv_transpose2d(x.view(-1, 4, l1, l2), self.kernel, stride=2)\n",
    "\n",
    "        if self.use_batch_dimension:\n",
    "            y = y.view(n_batch // 4, -1, 2 * l1, 2 * l2)\n",
    "            log_det_jacob = log_det_jacob.view(-1, 4).sum(dim=1)\n",
    "\n",
    "        else:\n",
    "            y = y.view(n_batch, -1, 2 * l1, 2 * l2)\n",
    "\n",
    "        return y, log_det_jacob\n",
    "\n",
    "    def inverse(self, y: Tensor, log_det_jacob: Tensor) -> tuple[Tensor]:\n",
    "        \"\"\"Downsample 4 lattice sites -> 1 lattice site.\"\"\"\n",
    "        n_batch, _, l1, l2 = y.shape\n",
    "        assert (l1 % 2 == 0) and (l2 % 2 == 0)\n",
    "\n",
    "        x = F.conv2d(y.view(-1, 1, l1, l2), self.kernel, stride=2)\n",
    "\n",
    "        if self.use_batch_dimension:\n",
    "            x = x.view(4 * n_batch, -1, l1 // 2, l2 // 2)\n",
    "            log_det_jacob_upsampled = torch.zeros(4 * log_det_jacob.shape[0], 1)\n",
    "            log_det_jacob_upsampled[::4] = log_det_jacob\n",
    "            log_det_jacob = log_det_jacob_upsampled\n",
    "        else:\n",
    "            x = x.view(n_batch, -1, l1 // 2, l2 // 2)\n",
    "\n",
    "        return x, log_det_jacob\n",
    "\n",
    "\n",
    "_test_input = torch.arange(64).view(1, 1, 8, 8).float()\n",
    "_test_ldj = torch.zeros([1])\n",
    "_test_layer = UpsamplingLayer(use_batch_dimension=True)\n",
    "_test_out1, _test_ldj = _test_layer.inverse(_test_input, _test_ldj)\n",
    "_test_out2, _test_ldj = _test_layer.inverse(_test_out1, _test_ldj)\n",
    "assert torch.allclose(_test_out2[0, 0], torch.Tensor([[0, 4], [32, 36]]))\n",
    "_test_out1_rt, _test_ldj = _test_layer.forward(_test_out2, _test_ldj)\n",
    "assert torch.allclose(_test_out1, _test_out1_rt)\n",
    "_test_input_rt, _test_ldj = _test_layer.forward(_test_out1_rt, _test_ldj)\n",
    "assert torch.allclose(_test_input, _test_input_rt)\n",
    "assert torch.allclose(_test_ldj, torch.zeros([1]))\n",
    "\n",
    "\n",
    "class GlobalRescalingLayer(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.log_scale = torch.nn.Parameter(torch.tensor([0.0]))\n",
    "\n",
    "    def forward(self, x: Tensor, log_det_jacob: Tensor) -> tuple[Tensor]:\n",
    "        x.mul_(self.log_scale.exp())\n",
    "        numel = utils.prod(x.shape[1:])\n",
    "        log_det_jacob.add_(self.log_scale.mul(numel))\n",
    "        return x, log_det_jacob\n",
    "\n",
    "    def inverse(self, y: Tensor, log_det_jacob: Tensor) -> tuple[Tensor]:\n",
    "        y.mul_(self.log_scale.neg().exp())\n",
    "        numel = utils.prod(y.shape[1:])\n",
    "        log_det_jacob.sub_(self.log_scale.mul(numel))\n",
    "        return y, log_det_jacob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e91af4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T15:12:36.314906Z",
     "start_time": "2022-03-30T15:12:36.303567Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultilevelFlow(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        #m_sq: float,\n",
    "        beta: float,\n",
    "        lam: NonNegativeFloat,\n",
    "        model_spec: list[dict | str],\n",
    "        # layers: list[Module],\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        n_upsampling = 0\n",
    "        for layer_spec in reversed(model_spec):\n",
    "            if layer_spec == \"upsampling\":\n",
    "                layers.insert(0, UpsamplingLayer(use_batch_dimension=True))\n",
    "                n_upsampling += 1\n",
    "            elif layer_spec == \"rescaling\":\n",
    "                layers.insert(0, GlobalRescalingLayer())\n",
    "            else:\n",
    "                transform = layer_spec[\"transform\"](**layer_spec[\"transform_spec\"])\n",
    "                layer = CouplingLayer(transform, layer_spec[\"net_spec\"])\n",
    "                layers.insert(0, layer)\n",
    "\n",
    "        self.flow = utils.Flow(*layers)\n",
    "        self.n_upsampling = n_upsampling\n",
    "        self.action = phi_four.PhiFourActionBeta(beta, lam)\n",
    "\n",
    "        self.curr_iter = 0\n",
    "\n",
    "        self.upsampling_layer = UpsamplingLayer(use_batch_dimension=True)\n",
    "\n",
    "    def _reshape_z(self, z):\n",
    "        for level in range(self.n_upsampling):\n",
    "            z, _ = self.upsampling_layer.inverse(z, torch.zeros([1]))\n",
    "        return z\n",
    "\n",
    "    def log_state(self, phi):\n",
    "        self.logger.experiment.add_histogram(\"phi\", phi.flatten(), self.curr_iter)\n",
    "        self.logger.experiment.add_histogram(\n",
    "            \"action\", self.action(phi).flatten(), self.curr_iter\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        z, log_prob_z = batch\n",
    "        z = self._reshape_z(z)\n",
    "        phi, log_det_jacob = self.flow(z)\n",
    "        weights = log_prob_z - log_det_jacob + self.action(phi)\n",
    "\n",
    "        self.curr_iter += 1\n",
    "        if self.curr_iter % 1000 == 0:\n",
    "            self.log_state(phi)\n",
    "\n",
    "        return phi, weights\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, weights = self.forward(batch)\n",
    "        loss = weights.mean()\n",
    "        self.log(\"loss\", loss, logger=True)\n",
    "        self.lr_schedulers().step()\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        phi, weights = self.forward(batch)\n",
    "        loss = weights.mean()\n",
    "        acceptance = utils.metropolis_acceptance(weights)\n",
    "        metrics = dict(loss=loss, acceptance=acceptance)\n",
    "        self.log_dict(metrics, prog_bar=False, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.flow.parameters(), lr=0.001)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=self.trainer.max_steps\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, prior: IterableDataset, n_iter: PositiveInt = 1):\n",
    "        phi, weights = self.forward(next(prior))\n",
    "        for _ in range(n_iter - 1):\n",
    "            _phi, _weights = self.forward(next(prior))\n",
    "            phi = torch.cat((phi, _phi), dim=0)\n",
    "            weights = torch.cat((weights, _weights), dim=0)\n",
    "        return phi, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d009aa",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e44213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T15:13:16.295178Z",
     "start_time": "2022-03-30T15:13:16.290452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Target theory\n",
    "LATTICE_LENGTH = 8\n",
    "# M_SQ = -4\n",
    "# LAM = 0.8\n",
    "BETA = 0.7\n",
    "LAM = 0.5\n",
    "\n",
    "# Model spec\n",
    "ADDITIVE_BLOCK = {\n",
    "    \"transform\": transforms.PointwiseAdditiveTransform,\n",
    "    \"transform_spec\": {},\n",
    "    \"net_spec\": {\n",
    "        \"hidden_shape\": [4, 4],\n",
    "        \"activation\": torch.nn.Tanh(),\n",
    "        \"final_activation\": torch.nn.Identity(),\n",
    "        \"use_bias\": False,\n",
    "    },\n",
    "}\n",
    "AFFINE_BLOCK = {\n",
    "    \"transform\": transforms.PointwiseAffineTransform,\n",
    "    \"transform_spec\": {},\n",
    "    \"net_spec\": {\n",
    "        \"hidden_shape\": [4, 4, 4, 4],\n",
    "        \"activation\": torch.nn.Tanh(),\n",
    "        \"final_activation\": torch.nn.Tanh(),\n",
    "        \"use_bias\": False,\n",
    "    },\n",
    "}\n",
    "SPLINE_BLOCK = {\n",
    "    \"transform\": transforms.PointwiseRationalQuadraticSplineTransform,\n",
    "    \"transform_spec\": {\"n_segments\": 8, \"interval\": (-4, 4)},\n",
    "    \"net_spec\": {\n",
    "        \"hidden_shape\": [4],\n",
    "        \"activation\": torch.nn.Tanh(),\n",
    "        \"final_activation\": torch.nn.Identity(),\n",
    "        \"use_bias\": True,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "MODEL_SPEC = [\n",
    "    AFFINE_BLOCK,\n",
    "    AFFINE_BLOCK,\n",
    "    \"rescaling\"\n",
    "]\n",
    "\n",
    "N_TRAIN = 1000\n",
    "N_BATCH = 1000\n",
    "N_BATCH_VAL = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70d86f96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T15:13:21.630653Z",
     "start_time": "2022-03-30T15:13:21.183823Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/david/miniconda3/envs/eflow/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1823: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n"
     ]
    }
   ],
   "source": [
    "# model = MultilevelFlow(\n",
    "#     m_sq=M_SQ,\n",
    "#     lam=LAM,\n",
    "#     model_spec=MODEL_SPEC,\n",
    "# )\n",
    "\n",
    "model = MultilevelFlow(\n",
    "    beta=BETA,\n",
    "    lam=LAM,\n",
    "    model_spec=MODEL_SPEC,\n",
    ")\n",
    "dist = torch.distributions.Normal(\n",
    "    loc=torch.zeros((LATTICE_LENGTH, LATTICE_LENGTH)),\n",
    "    scale=torch.ones((LATTICE_LENGTH, LATTICE_LENGTH)),\n",
    ")\n",
    "# dist = FreeScalarDistribution(LATTICE_LENGTH, M_SQ)\n",
    "train_dataloader = Prior(dist, sample_shape=[N_BATCH, 1])\n",
    "val_dataloader = Prior(dist, sample_shape=[N_BATCH_VAL, 1])\n",
    "\n",
    "pbar = utils.JlabProgBar()\n",
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval=\"step\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=0,\n",
    "    max_steps=N_TRAIN,  # total number of training steps\n",
    "    val_check_interval=100,  # how often to run sampling\n",
    "    limit_val_batches=1,  # one batch for each val step\n",
    "    callbacks=[pbar, lr_monitor],\n",
    "    enable_checkpointing=False,  # manually saving checkpoints\n",
    ")\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe9359ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T14:56:40.641134Z",
     "start_time": "2022-03-30T14:56:40.406662Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       acceptance           0.04820482060313225\n",
      "          loss              -58.00016403198242\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'loss': -58.00016403198242, 'acceptance': 0.04820482060313225}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model, val_dataloader)  # check acceptance before training starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1261b3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T14:56:17.650493Z",
     "start_time": "2022-03-30T14:55:38.000256Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type            | Params\n",
      "-----------------------------------------------------\n",
      "0 | flow             | Flow            | 2.2 K \n",
      "1 | upsampling_layer | UpsamplingLayer | 0     \n",
      "-----------------------------------------------------\n",
      "2.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1283e53f1314495b8b60ccd10157c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c171e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T10:03:22.823490Z",
     "start_time": "2022-03-29T10:03:22.798567Z"
    }
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25cd0f3",
   "metadata": {},
   "source": [
    "# Freestyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f4e56a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T14:31:42.702705Z",
     "start_time": "2022-03-28T14:31:42.688661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 8, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.sample().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea92f378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T11:45:04.319676Z",
     "start_time": "2022-03-28T11:45:04.303252Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18179/1874837325.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_18179/1713044713.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reshape_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_det_jacob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "model.forward(train_dataloader.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f1eebfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-28T19:47:18.558841Z",
     "start_time": "2022-03-28T19:47:18.552445Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = AFFINE_BLOCK[\"transform\"](**AFFINE_BLOCK[\"transform_spec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "2e5f9e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T12:02:36.461406Z",
     "start_time": "2022-03-30T12:02:36.457627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 8, 8])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7482710c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T15:14:42.540974Z",
     "start_time": "2022-03-30T15:14:41.924454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "val_dataloader = Prior(dist, sample_shape=[10000, 1])\n",
    "batch = val_dataloader.sample()\n",
    "\n",
    "flowed_batch, trash = model.flow(batch)\n",
    "\n",
    "plt.hist(flowed_batch.mean(axis=(1,2,3)).detach().numpy(), bins=100, density=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e28928b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T15:12:02.905103Z",
     "start_time": "2022-03-30T15:12:02.900236Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"b0.7-twomodes.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065b66b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T15:14:36.778881Z",
     "start_time": "2022-03-30T15:14:36.761636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"b0.7-twomodes.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09fdcc0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T14:35:20.221632Z",
     "start_time": "2022-03-29T14:35:20.214794Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = utils.make_checkerboard((8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a69dda5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T14:36:23.907093Z",
     "start_time": "2022-03-29T14:36:23.896776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 8, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.view(2,1,8,4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23e11b68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T14:37:24.231141Z",
     "start_time": "2022-03-29T14:37:24.224361Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "t = np.array([True,False,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c29799c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T14:37:27.456074Z",
     "start_time": "2022-03-29T14:37:27.445939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f4f1df1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T15:01:27.969248Z",
     "start_time": "2022-03-29T15:01:27.946071Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30248/3792732990.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "a.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "887eb18c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T15:29:32.011638Z",
     "start_time": "2022-03-29T15:29:32.003123Z"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor([1,2,3])\n",
    "t = torch.full([3],False)\n",
    "t[1] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a6d4b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T15:29:16.993001Z",
     "start_time": "2022-03-29T15:29:16.969948Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30248/1194551632.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "torch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46d2e93e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T15:30:05.658272Z",
     "start_time": "2022-03-29T15:30:05.647336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3dfdd39b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T15:29:41.321538Z",
     "start_time": "2022-03-29T15:29:41.309946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 3.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mul(~t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8487157",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T15:32:52.008825Z",
     "start_time": "2022-03-29T15:32:51.996676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2],[3,4]])[np.array([False,True]),...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e12848d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T16:01:53.184526Z",
     "start_time": "2022-03-29T16:01:53.172569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -2., -3.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.abs().neg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c02994c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-29T14:37:20.241268Z",
     "start_time": "2022-03-29T14:37:20.235028Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
